{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее Задание 3: Нейронные сети "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ваше имя:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загружаем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy import optimize\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1 : Применить все три метода для датасета о смертности (15 балов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загружаем датасет о смертности от рака в разных штатах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['avgAnnCount', 'avgDeathsPerYear', 'TARGET_deathRate', 'incidenceRate',\n",
      "       'medIncome', 'popEst2015', 'povertyPercent', 'studyPerCap', 'binnedInc',\n",
      "       'MedianAge', 'MedianAgeMale', 'MedianAgeFemale', 'Geography',\n",
      "       'AvgHouseholdSize', 'PercentMarried', 'PctNoHS18_24', 'PctHS18_24',\n",
      "       'PctSomeCol18_24', 'PctBachDeg18_24', 'PctHS25_Over',\n",
      "       'PctBachDeg25_Over', 'PctEmployed16_Over', 'PctUnemployed16_Over',\n",
      "       'PctPrivateCoverage', 'PctPrivateCoverageAlone', 'PctEmpPrivCoverage',\n",
      "       'PctPublicCoverage', 'PctPublicCoverageAlone', 'PctWhite', 'PctBlack',\n",
      "       'PctAsian', 'PctOtherRace', 'PctMarriedHouseholds', 'BirthRate',\n",
      "       'Unnamed: 34'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data_file = \"../data/cancer_regr.csv\"\n",
    "df = pd.read_csv(data_file, encoding = \"utf-8\" , engine='python')\n",
    "print(df.columns)\n",
    "\n",
    "# Выберем дополнительнуе фичи\n",
    "df_poverty =  df['povertyPercent']\n",
    "df_incidence = df['incidenceRate']\n",
    "df_death_rate = df['TARGET_deathRate']\n",
    "df_total_death = df['avgDeathsPerYear']\n",
    "df_med_income = df['medIncome']\n",
    "df_age = df['MedianAge']\n",
    "df_unemp = df['PctUnemployed16_Over']\n",
    "\n",
    "df = pd.concat([df_poverty, df_incidence, df_death_rate, df_total_death, df_med_income, df_age, df_unemp ], axis=1).dropna()\n",
    "\n",
    "\n",
    "# Найдем outlier\n",
    "z = np.abs(stats.zscore(df))\n",
    "threshold = 3\n",
    "\n",
    "# Уберем outlier\n",
    "df = df[(z < threshold).all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормализируем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализируем данные\n",
    "def normalize(data_frame):\n",
    "    mu = data_frame.mean()\n",
    "    sigma = data_frame.std()\n",
    "    scaled_data_frame = (data_frame.values-mu)/sigma\n",
    "    return scaled_data_frame\n",
    "\n",
    "# Poverty\n",
    "scaled_poverty = normalize(df['povertyPercent'])\n",
    "\n",
    "# Incident rate\n",
    "scaled_incident = normalize(df['incidenceRate'])\n",
    "\n",
    "# total Death\n",
    "scaled_t_death = normalize(df['avgDeathsPerYear'])\n",
    "\n",
    "# Med income\n",
    "scaled_m_income = normalize(df['medIncome'])\n",
    "\n",
    "# Average age\n",
    "scaled_age = normalize(df['MedianAge'])\n",
    "\n",
    "# Percent unemployed\n",
    "sclaed_unempl = normalize( df['PctUnemployed16_Over'])\n",
    "\n",
    "# Death Rate\n",
    "scaled_death_r = normalize(df['TARGET_deathRate'])\n",
    "\n",
    "\n",
    "# Определим датасет\n",
    "\n",
    "x_data = np.array([scaled_poverty,scaled_incident, scaled_t_death, scaled_m_income, scaled_age, sclaed_unempl]).transpose()\n",
    "\n",
    "y_data = np.expand_dims(scaled_death_r, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделяем дата на ТРИ выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of features in training data: (2297, 6)\n",
      "Shape of output in training data: (2297, 1)\n",
      "\n",
      "Shape of features in val data: (256, 6)\n",
      "Shape of output in val data: (256, 1)\n",
      "\n",
      "Shape of features in test data: (284, 6)\n",
      "Shape of output in test data: (284, 1)\n"
     ]
    }
   ],
   "source": [
    "# 10% данных будем использовать как validation dataset\n",
    "# 10% данных будем использовать как test dataset\n",
    "split_size = 0.1\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(x_data, y_data, test_size=split_size, shuffle=False)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=split_size, shuffle=False)\n",
    "\n",
    "print(\"\\nShape of features in training data: {}\".format(X_train.shape))\n",
    "print(\"Shape of output in training data: {}\".format(y_train.shape))\n",
    "\n",
    "print(\"\\nShape of features in val data: {}\".format(X_val.shape))\n",
    "print(\"Shape of output in val data: {}\".format(y_val.shape))\n",
    "\n",
    "print(\"\\nShape of features in test data: {}\".format(X_test.shape))\n",
    "print(\"Shape of output in test data: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1.1 Применить нейронную сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определить Dataset и DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определить структуру нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определить функцию ошибки, скорость апдейтов модели и способ оптимизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# тренировать сетку на датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определить хорошие гипер-параметры сети \n",
    "# (скорось апдейтов модели, количество слоев и нейроном, размер батча и т.д.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# применить на ТЕСТОВОЙ выборке и посчитать коэффициент детерминации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1.2 Применить метод К-ближайших соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Примерить метод К-ближайших соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подобрать опимальное значение К на утверждающей выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# применить на ТЕСТОВОЙ выборке и посчитать коэффициент детерминации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1.3 Применить полиномиальную регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построить полиномиальную регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подобрать опимальное значение степени полинома на утверждающей выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# применить на ТЕСТОВОЙ выборке и посчитать коэффициент детерминации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1.4 Какой метод дал лучше результат? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш ответ здесь:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2 : Применить все три метода для датасета о зарплатах (15 балов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Город', 'Years of experience', 'Стаж на текущем месте работы',\n",
      "       'Специализация', 'Salary', 'Прибавка к зарплате', 'Размер компании',\n",
      "       'Стаж', 'Стаж на текущем месте работы.1', 'ЗП'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Датасет 2: про зарплаты програмистов в Украине 10 лет назад\n",
    "data_file = \"../data/data_salaries_2010.csv\"\n",
    "df = pd.read_csv(data_file, encoding = \"utf-8\" , engine='python')\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# используйте ваш код из 2й домашки чтобы подготовить данные:\n",
    "# выбрать фичи, убрать outlier, нормализовать и т.д\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of features in training data: (2297, 6)\n",
      "Shape of output in training data: (2297, 1)\n",
      "\n",
      "Shape of features in val data: (256, 6)\n",
      "Shape of output in val data: (256, 1)\n",
      "\n",
      "Shape of features in test data: (284, 6)\n",
      "Shape of output in test data: (284, 1)\n"
     ]
    }
   ],
   "source": [
    "# разделим данные на три выборки\n",
    "# 10% данных будем использовать как validation dataset\n",
    "# 10% данных будем использовать как test dataset\n",
    "split_size = 0.1\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(x_data, y_data, test_size=split_size, shuffle=False)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=split_size, shuffle=False)\n",
    "\n",
    "print(\"\\nShape of features in training data: {}\".format(X_train.shape))\n",
    "print(\"Shape of output in training data: {}\".format(y_train.shape))\n",
    "\n",
    "print(\"\\nShape of features in val data: {}\".format(X_val.shape))\n",
    "print(\"Shape of output in val data: {}\".format(y_val.shape))\n",
    "\n",
    "print(\"\\nShape of features in test data: {}\".format(X_test.shape))\n",
    "print(\"Shape of output in test data: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Город', 'Years of experience', 'Стаж на текущем месте работы',\n",
      "       'Специализация', 'Salary', 'Прибавка к зарплате', 'Размер компании',\n",
      "       'Стаж', 'Стаж на текущем месте работы.1', 'ЗП'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Датасет 2: про зарплаты програмистов в Украине 10 лет назад\n",
    "data_file = \"../data/data_salaries_2010.csv\"\n",
    "df = pd.read_csv(data_file, encoding = \"utf-8\" , engine='python')\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2.1 Применить нейронную сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определить Dataset и DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определить структуру нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определить функцию ошибки, скорось апдейтов модели и способ оптимизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# тренировать сетку на датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определить хорошие гипер-параметры сети \n",
    "# (скорось апдейтов модели, количество слоев и нейроном, размер батча и т.д.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# применить на ТЕСТОВОЙ выборке и посчитать коэффициент детерминации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2.2 Применить метод К-ближайших соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Примерить метод К-ближайших соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подобрать опимальное значение К на утверждающей выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# применить на ТЕСТОВОЙ выборке и посчитать коэффициент детерминации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2.3 Применить полиномиальную регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построить полиномиальную регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подобрать опимальное значение степени полинома на утверждающей выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# применить на ТЕСТОВОЙ выборке и посчитать коэффициент детерминации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2.4 Какой метод дал лучше результат? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш ответ здесь:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3 : Применить все три метода для датасета о электричетсве (15 балов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Датасет 3 про потребления электричества в Стокгольме\n",
    "date_start = '2008-01-01'\n",
    "date_end = '2019-05-18'\n",
    "area = 'STH'\n",
    "url_base = 'https://mimer.svk.se/'\n",
    "url_target = 'ConsumptionProfile/DownloadText?groupByType=0&' + \\\n",
    "             'periodFrom='+date_start+'&' + \\\n",
    "             'periodTo='+date_end+'&' + \\\n",
    "             'networkAreaIdString='+area\n",
    "\n",
    "# \n",
    "url = url_base+url_target\n",
    "df_load = pd.read_csv(url, sep=';', header=1, decimal=',', usecols=[0,1], names=['Datetime', 'Load'])\n",
    "df_load = df_load[:-1]\n",
    "df_load.index = pd.to_datetime(df_load['Datetime'])\n",
    "df_load = df_load.drop(columns='Datetime')\n",
    "df_load['Load'] = -df_load['Load']/10**3\n",
    "\n",
    "location = ('Stockholm A', 98230)\n",
    "url = 'http://opendata-download-metobs.smhi.se/api/version/1.0/parameter/1/station/' + str(location[1]) + '/period/corrected-archive/data.csv'\n",
    "r = requests.get(url)\n",
    "decoded_content = r.content.decode('utf-8')\n",
    "data = list(csv.reader(decoded_content.splitlines(), delimiter=';'))\n",
    "\n",
    "header = 10\n",
    "datetime = []\n",
    "values = []\n",
    "for d in data[header:]:\n",
    "    datetime.append(d[0]+' '+d[1])\n",
    "    values.append(float(d[2]))\n",
    "df_temp = pd.DataFrame(data=values, index=pd.to_datetime(datetime), columns=['Temperature'])\n",
    "\n",
    "df = pd.concat([df_load, df_temp*10], axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# используйте ваш код из 2й домашки чтобы подготовить данные:\n",
    "# выбрать фичи, убрать outlier, нормализовать и т.д\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of features in training data: (2297, 6)\n",
      "Shape of output in training data: (2297, 1)\n",
      "\n",
      "Shape of features in val data: (256, 6)\n",
      "Shape of output in val data: (256, 1)\n",
      "\n",
      "Shape of features in test data: (284, 6)\n",
      "Shape of output in test data: (284, 1)\n"
     ]
    }
   ],
   "source": [
    "# разделим данные на три выборки\n",
    "# 10% данных будем использовать как validation dataset\n",
    "# 10% данных будем использовать как test dataset\n",
    "split_size = 0.1\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(x_data, y_data, test_size=split_size, shuffle=False)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=split_size, shuffle=False)\n",
    "\n",
    "print(\"\\nShape of features in training data: {}\".format(X_train.shape))\n",
    "print(\"Shape of output in training data: {}\".format(y_train.shape))\n",
    "\n",
    "print(\"\\nShape of features in val data: {}\".format(X_val.shape))\n",
    "print(\"Shape of output in val data: {}\".format(y_val.shape))\n",
    "\n",
    "print(\"\\nShape of features in test data: {}\".format(X_test.shape))\n",
    "print(\"Shape of output in test data: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3.1 Применить нейронную сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определить Dataset и DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определить структуру нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определить функцию ошибки, скорось апдейтов модели и способ оптимизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# тренировать сетку на датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определить хорошие гипер-параметры сети \n",
    "# (скорось апдейтов модели, количество слоев и нейроном, размер батча и т.д.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# применить на ТЕСТОВОЙ выборке и посчитать коэффициент детерминации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3.2 Применить метод К-ближайших соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Примерить метод К-ближайших соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подобрать опимальное значение К на утверждающей выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# применить на ТЕСТОВОЙ выборке и посчитать коэффициент детерминации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3.3 Применить полиномиальную регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построить полиномиальную регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подобрать опимальное значение степени полинома на утверждающей выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# применить на ТЕСТОВОЙ выборке и посчитать коэффициент детерминации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3.4 Какой метод дал лучше результат? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш ответ здесь:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4 (15 балов): Проанализировать какой метод лучше работает в каких обстоятельствах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# На основе результатов из заданий 1, 2 и 3 написать разсуждения на тему \"В каких случаях лучше использовать нейронные сетки, а когда - класические методы?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5 (20 балов): Использовать рекурентную сетку для прогнозирования нагрузки электричества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# использовать тот же датасет, что и раньше, но новый DataLoader, чтобы работать с последовательностями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определить структуру рекуррентной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определить функцию ошибки, скорось апдейтов модели и способ оптимизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# тренировать рекуррентную сетку на датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определить хорошие гипер-параметры сети \n",
    "# (скорось апдейтов модели, количество слоев и нейроном, размер батча и т.д.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# применить на ТЕСТОВОЙ выборке и посчитать коэфициент детерминации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 6 (допольнительное): Использовать и нагрузку и температуру на вход"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Это задание не обязательное и за него не будет баллов, оно для тех, кто хочет с этим поэкспериментировать"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "laba_env",
   "language": "python",
   "name": "laba_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
